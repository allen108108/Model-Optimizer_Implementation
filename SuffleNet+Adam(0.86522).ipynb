{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_function=ReduceLROnPlateau(monitor='val_acc',\n",
    "                             patience=3,\n",
    "                             verbose=1,\n",
    "                             factor=0.5,\n",
    "                             min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_batches = train_datagen.flow_from_directory('sample/train',\n",
    "                                                  target_size=(224,224),\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=8)\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "valid_batches = valid_datagen.flow_from_directory('sample/valid',\n",
    "                                                  target_size=(224,224),\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import backend as K\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.layers import Activation, Add, Concatenate, Conv2D, GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D,Input, Dense\n",
    "from keras.layers import MaxPool2D,AveragePooling2D, BatchNormalization, Lambda, DepthwiseConv2D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def channel_split(x, name=''):\n",
    "    # equipartition\n",
    "    in_channles = x.shape.as_list()[-1]\n",
    "    ip = in_channles // 2\n",
    "    c_hat = Lambda(lambda z: z[:, :, :, 0:ip], name='%s/sp%d_slice' % (name, 0))(x)\n",
    "    c = Lambda(lambda z: z[:, :, :, ip:], name='%s/sp%d_slice' % (name, 1))(x)\n",
    "    return c_hat, c\n",
    "\n",
    "def channel_shuffle(x):\n",
    "    height, width, channels = x.shape.as_list()[1:]\n",
    "    channels_per_split = channels // 2\n",
    "    x = K.reshape(x, [-1, height, width, 2, channels_per_split])\n",
    "    x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "    x = K.reshape(x, [-1, height, width, channels])\n",
    "    return x\n",
    "\n",
    "\n",
    "def shuffle_unit(inputs, out_channels, bottleneck_ratio,strides=2,stage=1,block=1):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = -1\n",
    "    else:\n",
    "        raise ValueError('Only channels last supported')\n",
    "\n",
    "    prefix = 'stage{}/block{}'.format(stage, block)\n",
    "    bottleneck_channels = int(out_channels * bottleneck_ratio)\n",
    "    if strides < 2:\n",
    "        c_hat, c = channel_split(inputs, '{}/spl'.format(prefix))\n",
    "        inputs = c\n",
    "\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=(1,1), strides=1, padding='same', name='{}/1x1conv_1'.format(prefix))(inputs)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_1'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_1'.format(prefix))(x)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', name='{}/3x3dwconv'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv'.format(prefix))(x)\n",
    "    x = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1conv_2'.format(prefix))(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_2'.format(prefix))(x)\n",
    "    x = Activation('relu', name='{}/relu_1x1conv_2'.format(prefix))(x)\n",
    "\n",
    "    if strides < 2:\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_1'.format(prefix))([x, c_hat])\n",
    "    else:\n",
    "        s2 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same', name='{}/3x3dwconv_2'.format(prefix))(inputs)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv_2'.format(prefix))(s2)\n",
    "        s2 = Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1_conv_3'.format(prefix))(s2)\n",
    "        s2 = BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_3'.format(prefix))(s2)\n",
    "        s2 = Activation('relu', name='{}/relu_1x1conv_3'.format(prefix))(s2)\n",
    "        ret = Concatenate(axis=bn_axis, name='{}/concat_2'.format(prefix))([x, s2])\n",
    "\n",
    "    ret = Lambda(channel_shuffle, name='{}/channel_shuffle'.format(prefix))(ret)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def block(x, channel_map, bottleneck_ratio, repeat=1, stage=1):\n",
    "    x = shuffle_unit(x, out_channels=channel_map[stage-1],\n",
    "                      strides=2,bottleneck_ratio=bottleneck_ratio,stage=stage,block=1)\n",
    "\n",
    "    for i in range(1, repeat+1):\n",
    "        x = shuffle_unit(x, out_channels=channel_map[stage-1],strides=1,\n",
    "                          bottleneck_ratio=bottleneck_ratio,stage=stage, block=(1+i))\n",
    "\n",
    "    return x\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "\n",
    "def ShuffleNetV2(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 scale_factor=1.0,\n",
    "                 pooling='max',\n",
    "                 input_shape=(224,224,3),\n",
    "                 load_model=None,\n",
    "                 num_shuffle_units=[3,7,3],\n",
    "                 bottleneck_ratio=1,\n",
    "                 classes=1000):\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('Only tensorflow supported for now')\n",
    "    name = 'ShuffleNetV2_{}_{}_{}'.format(scale_factor, bottleneck_ratio, \"\".join([str(x) for x in num_shuffle_units]))\n",
    "    input_shape = _obtain_input_shape(input_shape, default_size=224, min_size=28, require_flatten=include_top,\n",
    "                                      data_format=K.image_data_format())\n",
    "    out_dim_stage_two = {0.5:48, 1:116, 1.5:176, 2:244}\n",
    "\n",
    "    if pooling not in ['max', 'avg']:\n",
    "        raise ValueError('Invalid value for pooling')\n",
    "    if not (float(scale_factor)*4).is_integer():\n",
    "        raise ValueError('Invalid value for scale_factor, should be x over 4')\n",
    "    exp = np.insert(np.arange(len(num_shuffle_units), dtype=np.float32), 0, 0)  # [0., 0., 1., 2.]\n",
    "    out_channels_in_stage = 2**exp\n",
    "    out_channels_in_stage *= out_dim_stage_two[bottleneck_ratio]  #  calculate output channels for each stage\n",
    "    out_channels_in_stage[0] = 24  # first stage has always 24 output channels\n",
    "    out_channels_in_stage *= scale_factor\n",
    "    out_channels_in_stage = out_channels_in_stage.astype(int)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # create shufflenet architecture\n",
    "    x = Conv2D(filters=out_channels_in_stage[0], kernel_size=(3, 3), padding='same', use_bias=False, strides=(2, 2),\n",
    "               activation='relu', name='conv1')(img_input)\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='maxpool1')(x)\n",
    "\n",
    "    # create stages containing shufflenet units beginning at stage 2\n",
    "    for stage in range(len(num_shuffle_units)):\n",
    "        repeat = num_shuffle_units[stage]\n",
    "        x = block(x, out_channels_in_stage,\n",
    "                   repeat=repeat,\n",
    "                   bottleneck_ratio=bottleneck_ratio,\n",
    "                   stage=stage + 2)\n",
    "\n",
    "    if bottleneck_ratio < 2:\n",
    "        k = 1024\n",
    "    else:\n",
    "        k = 2048\n",
    "    x = Conv2D(k, kernel_size=1, padding='same', strides=1, name='1x1conv5_out', activation='relu')(x)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Dense(classes, name='fc')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    if input_tensor:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name=name)\n",
    "\n",
    "    if load_model:\n",
    "        model.load_weights('', by_name=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "    model = ShuffleNetV2(include_top=True, input_shape=(28,28,1), bottleneck_ratio=1)\n",
    "    plot_model(model, to_file='shufflenetv2.jpg', show_layer_names=True, show_shapes=True)\n",
    "\n",
    "\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 24) 648         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_1 (Conv2D (None, 56, 56, 116)  2900        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_1 (Bat (None, 56, 56, 116)  464         stage2/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_1 (A (None, 56, 56, 116)  0           stage2/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/3x3dwconv_2 (Dept (None, 28, 28, 24)   240         maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_3x3dwconv_2 (B (None, 28, 28, 24)   96          stage2/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_conv_3 (Conv2 (None, 28, 28, 116)  2900        stage2/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_1x1conv_3 (Bat (None, 28, 28, 116)  464         stage2/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_1x1conv_3 (A (None, 28, 28, 116)  0           stage2/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/concat_2 (Concate (None, 28, 28, 232)  0           stage2/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp1_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_1 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_1 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_1 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/3x3dwconv (Depthw (None, 28, 28, 116)  1160        stage2/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_3x3dwconv (Bat (None, 28, 28, 116)  464         stage2/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1conv_2 (Conv2D (None, 28, 28, 116)  13572       stage2/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_1x1conv_2 (Bat (None, 28, 28, 116)  464         stage2/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_1x1conv_2 (A (None, 28, 28, 116)  0           stage2/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/spl/sp0_slice (La (None, 28, 28, 116)  0           stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/concat_1 (Concate (None, 28, 28, 232)  0           stage2/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage2/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/channel_shuffle ( (None, 28, 28, 232)  0           stage2/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_1 (Conv2D (None, 28, 28, 232)  54056       stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_1 (Bat (None, 28, 28, 232)  928         stage3/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_1 (A (None, 28, 28, 232)  0           stage3/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/3x3dwconv_2 (Dept (None, 14, 14, 232)  2320        stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_3x3dwconv_2 (B (None, 14, 14, 232)  928         stage3/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_conv_3 (Conv2 (None, 14, 14, 232)  54056       stage3/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_1x1conv_3 (Bat (None, 14, 14, 232)  928         stage3/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_1x1conv_3 (A (None, 14, 14, 232)  0           stage3/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/concat_2 (Concate (None, 14, 14, 464)  0           stage3/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block5/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block5/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block5/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block5/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block5/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block5/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block5/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block5/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block6/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block6/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block6/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block6/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block6/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block6/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block6/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block6/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block7/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block7/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block7/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block7/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block7/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block7/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block7/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block7/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp1_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_1 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_1 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_1 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/3x3dwconv (Depthw (None, 14, 14, 232)  2320        stage3/block8/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_3x3dwconv (Bat (None, 14, 14, 232)  928         stage3/block8/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1conv_2 (Conv2D (None, 14, 14, 232)  54056       stage3/block8/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_1x1conv_2 (Bat (None, 14, 14, 232)  928         stage3/block8/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_1x1conv_2 (A (None, 14, 14, 232)  0           stage3/block8/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/spl/sp0_slice (La (None, 14, 14, 232)  0           stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/concat_1 (Concate (None, 14, 14, 464)  0           stage3/block8/relu_1x1conv_2[0][0\n",
      "                                                                 stage3/block8/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/channel_shuffle ( (None, 14, 14, 464)  0           stage3/block8/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_1 (Conv2D (None, 14, 14, 464)  215760      stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_1 (Bat (None, 14, 14, 464)  1856        stage4/block1/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_1 (A (None, 14, 14, 464)  0           stage4/block1/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block1/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/3x3dwconv_2 (Dept (None, 7, 7, 464)    4640        stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_3x3dwconv_2 (B (None, 7, 7, 464)    1856        stage4/block1/3x3dwconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_conv_3 (Conv2 (None, 7, 7, 464)    215760      stage4/block1/bn_3x3dwconv_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_1x1conv_3 (Bat (None, 7, 7, 464)    1856        stage4/block1/1x1_conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_1x1conv_3 (A (None, 7, 7, 464)    0           stage4/block1/bn_1x1conv_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat_2 (Concate (None, 7, 7, 928)    0           stage4/block1/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block1/relu_1x1conv_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block1/concat_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block2/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block2/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block2/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block2/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block2/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block2/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block2/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block2/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block3/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block3/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block3/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block3/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block3/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block3/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block3/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block3/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp1_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_1 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/spl/sp1_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_1 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_1 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/3x3dwconv (Depthw (None, 7, 7, 464)    4640        stage4/block4/relu_1x1conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_3x3dwconv (Bat (None, 7, 7, 464)    1856        stage4/block4/3x3dwconv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1conv_2 (Conv2D (None, 7, 7, 464)    215760      stage4/block4/bn_3x3dwconv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_1x1conv_2 (Bat (None, 7, 7, 464)    1856        stage4/block4/1x1conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_1x1conv_2 (A (None, 7, 7, 464)    0           stage4/block4/bn_1x1conv_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/spl/sp0_slice (La (None, 7, 7, 464)    0           stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/concat_1 (Concate (None, 7, 7, 928)    0           stage4/block4/relu_1x1conv_2[0][0\n",
      "                                                                 stage4/block4/spl/sp0_slice[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 7, 7, 928)    0           stage4/block4/concat_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "1x1conv5_out (Conv2D)           (None, 7, 7, 1024)   951296      stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (GlobalMaxPooli (None, 1024)         0           1x1conv5_out[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 2)            2050        global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 2)            0           fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 4,020,790\n",
      "Trainable params: 3,992,670\n",
      "Non-trainable params: 28,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=ShuffleNetV2(input_shape=(224,224,3),classes=2)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam' , loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 39s 154ms/step - loss: 1.2752 - acc: 0.5465 - val_loss: 2.6113 - val_acc: 0.5200\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 26s 106ms/step - loss: 0.8179 - acc: 0.5425 - val_loss: 1.3751 - val_acc: 0.5170\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.7213 - acc: 0.5755 - val_loss: 1.0160 - val_acc: 0.5890\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.6754 - acc: 0.6010 - val_loss: 0.7062 - val_acc: 0.5830\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.6598 - acc: 0.6010 - val_loss: 0.6796 - val_acc: 0.6050\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.6477 - acc: 0.6270 - val_loss: 0.6325 - val_acc: 0.6540\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.6462 - acc: 0.6265 - val_loss: 0.6424 - val_acc: 0.6470\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.6408 - acc: 0.6285 - val_loss: 0.6202 - val_acc: 0.6590\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.6350 - acc: 0.6400 - val_loss: 0.6269 - val_acc: 0.6480\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.6203 - acc: 0.6530 - val_loss: 0.6188 - val_acc: 0.6500\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 0.6171 - acc: 0.6525 - val_loss: 0.5945 - val_acc: 0.6910\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.6189 - acc: 0.6460 - val_loss: 0.7721 - val_acc: 0.6650\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.6167 - acc: 0.6590 - val_loss: 0.6152 - val_acc: 0.6690\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.6068 - acc: 0.6715 - val_loss: 0.6421 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.5812 - acc: 0.6845 - val_loss: 0.5710 - val_acc: 0.7240\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.5748 - acc: 0.6910 - val_loss: 0.5964 - val_acc: 0.6670\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.5735 - acc: 0.7070 - val_loss: 0.6025 - val_acc: 0.6580\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.5673 - acc: 0.7065 - val_loss: 0.7062 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 32s 126ms/step - loss: 0.5299 - acc: 0.7225 - val_loss: 0.5413 - val_acc: 0.7120\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 34s 135ms/step - loss: 0.5161 - acc: 0.7355 - val_loss: 0.5485 - val_acc: 0.7130\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.5083 - acc: 0.7425 - val_loss: 0.5524 - val_acc: 0.7260\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.5049 - acc: 0.7375 - val_loss: 0.4966 - val_acc: 0.7400\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.5000 - acc: 0.7540 - val_loss: 0.8566 - val_acc: 0.6120\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.4992 - acc: 0.7485 - val_loss: 0.5782 - val_acc: 0.7270\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4728 - acc: 0.7745 - val_loss: 0.4741 - val_acc: 0.7730\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.4725 - acc: 0.7720 - val_loss: 0.5536 - val_acc: 0.7380\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.4606 - acc: 0.7765 - val_loss: 0.4706 - val_acc: 0.7760\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4392 - acc: 0.7940 - val_loss: 0.5452 - val_acc: 0.7310\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.4361 - acc: 0.7890 - val_loss: 0.5349 - val_acc: 0.7410\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4305 - acc: 0.7890 - val_loss: 0.4965 - val_acc: 0.7790\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4200 - acc: 0.8020 - val_loss: 0.4788 - val_acc: 0.7670\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.3916 - acc: 0.8270 - val_loss: 0.4654 - val_acc: 0.7940\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.3782 - acc: 0.8395 - val_loss: 0.6754 - val_acc: 0.7400\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.3944 - acc: 0.8240 - val_loss: 0.4483 - val_acc: 0.7940\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.3701 - acc: 0.8325 - val_loss: 0.4827 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 29s 114ms/step - loss: 0.3342 - acc: 0.8525 - val_loss: 0.4763 - val_acc: 0.7990\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.3158 - acc: 0.8655 - val_loss: 0.4994 - val_acc: 0.7850\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.3092 - acc: 0.8595 - val_loss: 0.4020 - val_acc: 0.8070\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.2969 - acc: 0.8695 - val_loss: 0.3994 - val_acc: 0.8220\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.2928 - acc: 0.8795 - val_loss: 0.4914 - val_acc: 0.7800\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.2786 - acc: 0.8860 - val_loss: 0.4818 - val_acc: 0.7870\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.2601 - acc: 0.8825 - val_loss: 0.4874 - val_acc: 0.7970\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.2299 - acc: 0.9005 - val_loss: 0.4045 - val_acc: 0.8260\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.2269 - acc: 0.9120 - val_loss: 0.4046 - val_acc: 0.8140\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.2156 - acc: 0.9025 - val_loss: 0.4390 - val_acc: 0.8180\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.2070 - acc: 0.9145 - val_loss: 0.4207 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.2015 - acc: 0.9165 - val_loss: 0.4260 - val_acc: 0.8260\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1730 - acc: 0.9295 - val_loss: 0.4095 - val_acc: 0.8250\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.1747 - acc: 0.9320 - val_loss: 0.3938 - val_acc: 0.8350\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1785 - acc: 0.9265 - val_loss: 0.4158 - val_acc: 0.8340\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1661 - acc: 0.9350 - val_loss: 0.4414 - val_acc: 0.8350\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.1790 - acc: 0.9240 - val_loss: 0.4056 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.1556 - acc: 0.9410 - val_loss: 0.4112 - val_acc: 0.8320\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.1457 - acc: 0.9440 - val_loss: 0.4264 - val_acc: 0.8330\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1520 - acc: 0.9425 - val_loss: 0.4225 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1403 - acc: 0.9440 - val_loss: 0.4232 - val_acc: 0.8380\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.1448 - acc: 0.9425 - val_loss: 0.4193 - val_acc: 0.8360\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.1442 - acc: 0.9425 - val_loss: 0.4183 - val_acc: 0.8350\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.1480 - acc: 0.9350 - val_loss: 0.4194 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.1363 - acc: 0.9440 - val_loss: 0.4248 - val_acc: 0.8340\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.1286 - acc: 0.9480 - val_loss: 0.4206 - val_acc: 0.8380\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1332 - acc: 0.9445 - val_loss: 0.4197 - val_acc: 0.8350\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.1423 - acc: 0.9440 - val_loss: 0.4193 - val_acc: 0.8340\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1329 - acc: 0.9485 - val_loss: 0.4223 - val_acc: 0.8350\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.1201 - acc: 0.9540 - val_loss: 0.4233 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.1388 - acc: 0.9410 - val_loss: 0.4252 - val_acc: 0.8370\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.1498 - acc: 0.9375 - val_loss: 0.4233 - val_acc: 0.8370\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1475 - acc: 0.9425 - val_loss: 0.4224 - val_acc: 0.8410\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.1387 - acc: 0.9390 - val_loss: 0.4214 - val_acc: 0.8360\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 49s 197ms/step - loss: 0.1375 - acc: 0.9455 - val_loss: 0.4219 - val_acc: 0.8390\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 43s 170ms/step - loss: 0.1311 - acc: 0.9435 - val_loss: 0.4212 - val_acc: 0.8370\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 41s 162ms/step - loss: 0.1294 - acc: 0.9460 - val_loss: 0.4195 - val_acc: 0.8390\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 41s 164ms/step - loss: 0.1343 - acc: 0.9400 - val_loss: 0.4240 - val_acc: 0.8380\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.1336 - acc: 0.9515 - val_loss: 0.4222 - val_acc: 0.8400\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 41s 164ms/step - loss: 0.1245 - acc: 0.9515 - val_loss: 0.4245 - val_acc: 0.8360\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.1346 - acc: 0.9450 - val_loss: 0.4258 - val_acc: 0.8400\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1481 - acc: 0.9445 - val_loss: 0.4243 - val_acc: 0.8380\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.1236 - acc: 0.9520 - val_loss: 0.4234 - val_acc: 0.8390\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1311 - acc: 0.9500 - val_loss: 0.4200 - val_acc: 0.8380\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1424 - acc: 0.9445 - val_loss: 0.4238 - val_acc: 0.8390\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.1273 - acc: 0.9480 - val_loss: 0.4240 - val_acc: 0.8380\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.1334 - acc: 0.9485 - val_loss: 0.4224 - val_acc: 0.8380\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1359 - acc: 0.9460 - val_loss: 0.4246 - val_acc: 0.8390\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1367 - acc: 0.9455 - val_loss: 0.4215 - val_acc: 0.8350\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 0.1292 - acc: 0.9455 - val_loss: 0.4272 - val_acc: 0.8380\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1267 - acc: 0.9500 - val_loss: 0.4244 - val_acc: 0.8390\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1473 - acc: 0.9390 - val_loss: 0.4238 - val_acc: 0.8370\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1273 - acc: 0.9505 - val_loss: 0.4233 - val_acc: 0.8360\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1287 - acc: 0.9480 - val_loss: 0.4269 - val_acc: 0.8390\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 0.1333 - acc: 0.9490 - val_loss: 0.4224 - val_acc: 0.8360\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 0.1429 - acc: 0.9445 - val_loss: 0.4244 - val_acc: 0.8350\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.1399 - acc: 0.9440 - val_loss: 0.4255 - val_acc: 0.8370\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 29s 114ms/step - loss: 0.1322 - acc: 0.9505 - val_loss: 0.4254 - val_acc: 0.8360\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1266 - acc: 0.9515 - val_loss: 0.4233 - val_acc: 0.8390\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1391 - acc: 0.9470 - val_loss: 0.4286 - val_acc: 0.8380\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 32s 126ms/step - loss: 0.1320 - acc: 0.9440 - val_loss: 0.4245 - val_acc: 0.8390\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.1327 - acc: 0.9495 - val_loss: 0.4293 - val_acc: 0.8400\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 29s 114ms/step - loss: 0.1356 - acc: 0.9500 - val_loss: 0.4297 - val_acc: 0.8410\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.1327 - acc: 0.9450 - val_loss: 0.4266 - val_acc: 0.8380\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1318 - acc: 0.9445 - val_loss: 0.4294 - val_acc: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6f36ca940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batches,\n",
    "                    steps_per_epoch = train_batches.samples // 8,\n",
    "                    validation_data = valid_batches,\n",
    "                    validation_steps = valid_batches.samples // 8,\n",
    "                    epochs = 100,\n",
    "                    callbacks=[LR_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('shuffleNet-v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45005780359730124, 0.8425]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory('sample/test',\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  batch_size=8,\n",
    "                                                  class_mode='categorical')\n",
    "model.evaluate_generator(test_generator, steps=50)\n",
    "#test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "#print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path = \"./test/\"\n",
    "\n",
    "files=os.listdir(path)\n",
    "\n",
    "X_test = []\n",
    "\n",
    "\n",
    "for file in files:\n",
    "        img_array = cv2.imread(os.path.join(path,file))\n",
    "        new_img_array = cv2.resize(img_array, dsize=(224,224))\n",
    "        X_test.append(new_img_array)   \n",
    "        \n",
    "X_test = np.array(X_test).reshape(-1,224,224,3)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.787219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.519258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.865173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Predicted\n",
       "0   0   0.046306\n",
       "1   1   0.996173\n",
       "2   2   0.787219\n",
       "3   3   0.519258\n",
       "4   4   0.865173"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.read_csv('sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961732737507212"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[1,'Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(400):\n",
    "    sub.loc[i,'Predicted']=predictions[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.906775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.031489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.986432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Predicted\n",
       "0   0   0.024814\n",
       "1   1   0.906775\n",
       "2   2   0.995427\n",
       "3   3   0.031489\n",
       "4   4   0.986432"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
